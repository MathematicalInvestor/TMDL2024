{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanjayvonk/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from skimage import data\n",
    "from skimage.util import montage \n",
    "import skimage.transform as skTrans\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageOps  \n",
    "\n",
    "\n",
    "# neural imaging\n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "# !pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \n",
    "# import gif_your_nifti.core as gif2nif\n",
    "\n",
    "\n",
    "# ml libs\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE seg-areas  \n",
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
    "}\n",
    "\n",
    "# there are 155 slices per volume\n",
    "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
    "VOLUME_SLICES = 100 \n",
    "VOLUME_START_AT = 22 # first slice of volume that we will include\n",
    "IMG_SIZE=128\n",
    "\n",
    "TRAIN_DATASET_PATH = '/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "VALIDATION_DATASET_PATH = '/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss as defined above for 4 classes\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "#    K.print_tensor(total_loss, message=' total dice coef: ')\n",
    "    return total_loss\n",
    "\n",
    "\n",
    " \n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "\n",
    "def build_unet(inputs, ker_init, dropout):\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
    "train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories); \n",
    "    \n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "                    \n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show number of data for each dir \n",
    "def showDataLayout():\n",
    "    plt.bar([\"Train\",\"Valid\",\"Test\"],\n",
    "    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylabel('Number of images')\n",
    "    plt.title('Data distribution')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "showDataLayout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
    "#                               patience=2, verbose=1, mode='auto'),\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1),\n",
    "#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
    "#                             verbose=1, save_best_only=True, save_weights_only = True)\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# history =  model.fit(training_generator,\n",
    "#                     epochs=35,\n",
    "#                     steps_per_epoch=len(train_ids),\n",
    "#                     callbacks= callbacks,\n",
    "#                     validation_data = valid_generator\n",
    "#                     )  \n",
    "# model.save(\"model_x1_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ load trained model ################\n",
    "model = keras.models.load_model('/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/model_per_class.h5', \n",
    "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                                                   \"dice_coef\": dice_coef,\n",
    "                                                   \"precision\": precision,\n",
    "                                                   \"sensitivity\":sensitivity,\n",
    "                                                   \"specificity\":specificity,\n",
    "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
    "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
    "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
    "                                                  }, compile=False)\n",
    "\n",
    "history = pd.read_csv('/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/training_per_class.log', sep=',', engine='python')\n",
    "\n",
    "hist=history\n",
    "\n",
    "############### ########## ####### #######\n",
    "\n",
    "# hist=history.history\n",
    "\n",
    "acc=hist['accuracy']\n",
    "val_acc=hist['val_accuracy']\n",
    "\n",
    "epoch=range(len(acc))\n",
    "\n",
    "loss=hist['loss']\n",
    "val_loss=hist['val_loss']\n",
    "\n",
    "train_dice=hist['dice_coef']\n",
    "val_dice=hist['val_dice_coef']\n",
    "\n",
    "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
    "\n",
    "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
    "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
    "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
    "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
    "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n",
    "# returns volume of specified study at `path`\n",
    "def imageLoader(path):\n",
    "    image = nib.load(path).get_fdata()\n",
    "    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "# load nifti file at `path`\n",
    "# and load each slice with mask from volume\n",
    "# choose the mri type & resize to `IMG_SIZE`\n",
    "def loadDataFromDir(path, list_of_files, mriType, n_images):\n",
    "    scans = []\n",
    "    masks = []\n",
    "    for i in list_of_files[:n_images]:\n",
    "        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n",
    "        currentScanVolume = imageLoader(fullPath)\n",
    "        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n",
    "        # for each slice in 3D volume, find also it's mask\n",
    "        for j in range(0, currentScanVolume.shape[2]):\n",
    "            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            scans.append(scan_img[..., np.newaxis])\n",
    "            masks.append(mask_img[..., np.newaxis])\n",
    "    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n",
    "        \n",
    "#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByPath(case_path, case):\n",
    "    files = next(os.walk(case_path))[2]\n",
    "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
    "  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n",
    "    flair=nib.load(vol_path).get_fdata()\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n",
    "    ce=nib.load(vol_path).get_fdata() \n",
    "    \n",
    " #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n",
    " #   seg=nib.load(vol_path).get_fdata()  \n",
    "\n",
    "    \n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    " #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n",
    "    return model.predict(X/np.max(X), verbose=1)\n",
    "\n",
    "def showPredictsById(case, start_slice = 60):\n",
    "    path = f\"/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "    p = predictByPath(path,case)\n",
    "\n",
    "    core = p[:,:,:,1]\n",
    "    edema= p[:,:,:,2]\n",
    "    enhancing = p[:,:,:,3]\n",
    "\n",
    "    plt.figure(figsize=(18, 50))\n",
    "    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n",
    "\n",
    "    for i in range(6): # for each image, add brain background\n",
    "        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
    "    \n",
    "    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
    "    axarr[0].title.set_text('Original image flair')\n",
    "    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
    "    axarr[1].title.set_text('Ground truth')\n",
    "    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
    "    axarr[2].title.set_text('all classes')\n",
    "    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
    "    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
    "    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "showPredictsById(case=test_ids[0][-3:])\n",
    "showPredictsById(case=test_ids[1][-3:])\n",
    "showPredictsById(case=test_ids[2][-3:])\n",
    "showPredictsById(case=test_ids[3][-3:])\n",
    "showPredictsById(case=test_ids[4][-3:])\n",
    "showPredictsById(case=test_ids[5][-3:])\n",
    "showPredictsById(case=test_ids[6][-3:])\n",
    "\n",
    "\n",
    "# mask = np.zeros((10,10))\n",
    "# mask[3:-3, 3:-3] = 1 # white square in black background\n",
    "# im = mask + np.random.randn(10,10) * 0.01 # random image\n",
    "# masked = np.ma.masked_where(mask == 0, mask)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(im, 'gray', interpolation='none')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(im, 'gray', interpolation='none')\n",
    "# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 245\n",
    "path = f\"/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "gt = cv2.resize(gt, (IMG_SIZE, IMG_SIZE))[:, :, VOLUME_START_AT:VOLUME_START_AT+VOLUME_SLICES]\n",
    "gt[gt == 4] = 3\n",
    "gt = gt.astype(int)\n",
    "origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    " = predictByPath(path,case)\n",
    "p = np.transpose(p, (1, 2, 0, 3))\n",
    "core = p[:,:,:,1]\n",
    "edema= p[:,:,:,2]\n",
    "enhancing = p[:,:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = IMG_SIZE * IMG_SIZE * VOLUME_SLICES\n",
    "alpha = 0.05\n",
    "\n",
    "gt_flat = gt.reshape(-1)\n",
    "p_flat = p.reshape(-1, p.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Calibration case\n",
    "case = 245\n",
    "path = f\"/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "cal_gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "cal_gt = cv2.resize(gt, (IMG_SIZE, IMG_SIZE))[:, :, VOLUME_START_AT:VOLUME_START_AT+VOLUME_SLICES]\n",
    "cal_gt = cal_gt.astype(int)\n",
    "cal_gt[cal_gt == 4] = 3\n",
    "origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "cal_smx = predictByPath(path,case)\n",
    "cal_smx = np.transpose(cal_smx, (1, 2, 0, 3))\n",
    "\n",
    "# Get scores.\n",
    "cal_smx = cal_smx.reshape(-1, p.shape[-1])\n",
    "cal_labels = cal_gt.reshape(-1)\n",
    "cal_pi = cal_smx.argsort(1)[:,::-1]; cal_srt = np.take_along_axis(cal_smx, cal_pi, axis=1).cumsum(axis=1)\n",
    "cal_scores = np.take_along_axis(cal_srt,cal_pi.argsort(axis=1),axis=1)[range(n),cal_labels]\n",
    "# Get the score quantile\n",
    "qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, interpolation='higher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 179\n",
    "path = f\"/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "gt = cv2.resize(gt, (IMG_SIZE, IMG_SIZE))[:, :, VOLUME_START_AT:VOLUME_START_AT+VOLUME_SLICES]\n",
    "gt[gt == 4] = 3\n",
    "gt = gt.astype(int)\n",
    "origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "val_smx = predictByPath(path,case)\n",
    "val_smx = np.transpose(cal_smx, (1, 2, 0, 3))\n",
    "# Deploy\n",
    "val_pi = val_smx.argsort(1)[:,::-1]; val_srt = np.take_along_axis(val_smx,val_pi,axis=1).cumsum(axis=1)\n",
    "prediction_sets = np.take_along_axis(val_srt <= qhat,val_pi.argsort(axis=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 179\n",
    "path = f\"/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "p = predictByPath(path,case)\n",
    "p = np.transpose(p, (1, 2, 0, 3))\n",
    "core = p[:,:,:,1]\n",
    "edema= p[:,:,:,2]\n",
    "enhancing = p[:,:,:,3]\n",
    "\n",
    "start_slice=60\n",
    "plt.figure(figsize=(18, 50))\n",
    "f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n",
    "\n",
    "for i in range(6): # for each image, add brain background\n",
    "    axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
    "\n",
    "axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
    "axarr[0].title.set_text('Original image flair')\n",
    "curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
    "axarr[1].title.set_text('Ground truth')\n",
    "axarr[2].imshow(p[:,:,start_slice,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
    "axarr[2].title.set_text('all classes')\n",
    "axarr[3].imshow(edema[:,:,start_slice], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
    "axarr[4].imshow(core[:,:,start_slice], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
    "axarr[5].imshow(enhancing[:,:,start_slice], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "val_directory = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "conformal_ids = pathListIntoIds(val_directory); \n",
    "\n",
    "conformal_train, conformal_test = train_test_split(conformal_ids,test_size=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_train, conformal_test = train_test_split(val_ids,test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(case):\n",
    "    path = f\"/Users/sanjayvonk/Development/Work/TMDL2024/Research Project/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case[-3:]}\"\n",
    "    ground_truth = nib.load(os.path.join(path, f'BraTS20_Training_{case[-3:]}_seg.nii')).get_fdata()\n",
    "    original_image = nib.load(os.path.join(path, f'BraTS20_Training_{case[-3:]}_flair.nii')).get_fdata()\n",
    "    soft_max = predictByPath(path,case[-3:])\n",
    "    soft_max = np.transpose(p, (1, 2, 0, 3))\n",
    "    \n",
    "    return original_image, soft_max, ground_truth\n",
    "\n",
    "def process_and_store_data(id_list):\n",
    "    \"\"\"\n",
    "    Process each dataset in id_list and store or return for further processing.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for case_id in id_list:\n",
    "        origImage, sftmax, gt = load_data(case_id)\n",
    "        \n",
    "        all_data.append((origImage, sftmax, gt))\n",
    "        \n",
    "    return all_data\n",
    "\n",
    "conformal_train_data = process_and_store_data(conformal_train[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
